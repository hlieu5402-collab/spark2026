# 教案级注释说明：
# - 背景：SRE 希望将 ReadyState 四分支转换为可直接操作的告警策略。
# - 设计要点：统一使用 5 分钟滑窗的 `increase()` 观察事件频率，配合 `sum by (...)` 固定标签，以避免高基数。
# - 关键输出：三条告警分别映射 Busy（需扩缩容或排查依赖）、Budget Exhausted（触发限流/降级）、RetryAfter Burst（扩展退避策略）。
# - 前置条件：服务必须按 docs/observability/metrics.md 中的约定上报指标，尤其是 `spark_request_ready_state_total` 和 `spark_request_retry_after_total`。
# - 后置条件：告警被触发时，能携带 service/route/operation 等上下文，Runbook 可直接定位。
---
# Prometheus 规则文件，使用 `promtool check rules` 进行语法校验。
groups:
  - name: spark-ready-state
    rules:
      - alert: SparkServiceBusySustained
        expr: |
          # 意图 (R1)：衡量 ReadyState 中 Busy 事件在 5 分钟窗口内的占比，超过 30% 说明服务持续处于繁忙态。
          # 逻辑 (R2)：分子使用 Busy 事件数，分母使用所有 ReadyState 事件数，通过比值判断是否进入告警线。
          # 契约 (R3)：要求指标包含 `service_name`、`route_id`、`operation`、`protocol` 标签；无数据时 Prometheus 自动视为 0，不触发告警。
          # 考量 (R4)：选择 30% 阈值以兼顾短暂抖动（不会触发）与持续压力（会触发）；如需更敏感可下调。
          sum by (service_name, route_id, operation, protocol) (
            increase(spark_request_ready_state_total{ready_state="busy"}[5m])
          )
          /
          clamp_min(
            sum by (service_name, route_id, operation, protocol) (
              increase(spark_request_ready_state_total[5m])
            ),
            1
          )
          > 0.3
        for: 5m
        labels:
          severity: page
          runbook: https://git.example.com/spark2026/docs/runbook/service-error-rate.md
        annotations:
          summary: "{{ $labels.service_name }}({{ $labels.route_id }}) ReadyState Busy 占比 >30%"
          description: |
            ReadyState Busy 占比在 5 分钟内超过 30%。请检查依赖、排队深度和流量是否异常。

      - alert: SparkServiceBudgetExhaustedSpike
        expr: |
          # 意图：捕捉预算耗尽事件，一旦出现说明服务已经无法接收新流量。
          # 逻辑：直接统计 5 分钟内 BudgetExhausted 次数，阈值设为 >=1。
          # 契约：需要指标提供 `ready_state="budget_exhausted"` 事件。
          # 考量：采用 `sum` 而非占比，以便在低流量场景下也能即时响应。
          sum by (service_name, route_id, operation, protocol) (
            increase(spark_request_ready_state_total{ready_state="budget_exhausted"}[5m])
          )
          >= 1
        for: 1m
        labels:
          severity: critical
          runbook: https://git.example.com/spark2026/docs/runbook/service-error-rate.md
        annotations:
          summary: "{{ $labels.service_name }}({{ $labels.route_id }}) 流量预算耗尽"
          description: |
            过去 5 分钟内出现 BudgetExhausted 事件。立即评估限流、降级或扩容措施，避免服务全面拒绝请求。

      - alert: SparkServiceRetryAfterBurst
        expr: |
          # 意图：识别 RetryAfter 信号的集中爆发，为 Runbook 中的退避/限流策略提供触发条件。
          # 逻辑：聚合 RetryAfter 事件总数，阈值为 5 分钟内 >=5 次，同时要求 ReadyState 中 RetryAfter 占比 >=10%。
          # 契约：依赖 `spark_request_retry_after_total` 与 `spark_request_ready_state_total{ready_state="retry_after"}` 指标。
          # 考量：双重条件可以过滤掉单次 RetryAfter（例如灰度更新）导致的误报，也能应对高流量场景的真实退避需求。
          sum by (service_name, route_id, operation, protocol) (
            increase(spark_request_retry_after_total[5m])
          )
          >= 5
          and
          sum by (service_name, route_id, operation, protocol) (
            increase(spark_request_ready_state_total{ready_state="retry_after"}[5m])
          )
          /
          clamp_min(
            sum by (service_name, route_id, operation, protocol) (
              increase(spark_request_ready_state_total[5m])
            ),
            1
          )
          >= 0.1
        for: 2m
        labels:
          severity: warning
          runbook: https://git.example.com/spark2026/docs/runbook/retry-after.md
        annotations:
          summary: "{{ $labels.service_name }}({{ $labels.route_id }}) RetryAfter 集中爆发"
          description: |
            过去 5 分钟内产生 {{ $value | humanize }} 次 RetryAfter，且占 ReadyState 总量的 10% 以上。请按照 Runbook 扩展退避、限流或降级策略。
